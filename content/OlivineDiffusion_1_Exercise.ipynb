{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b430b11",
   "metadata": {},
   "source": [
    "# Olivine Diffusion - 1\n",
    "## Introduction to Regression Problems in Geochemistry\n",
    "\n",
    "*Course: Geochemical Modelling*  \n",
    "*Duration: 12 hours*  \n",
    "*Target: Master 2 students*  \n",
    "(c) Charles Le Losq\n",
    "\n",
    "---\n",
    "\n",
    "## Course Overview\n",
    "\n",
    "This notebook series provides a comprehensive introduction to **regression analysis in geochemistry** using olivine diffusion as a real-world case study. We'll progress from basic fitting to advanced uncertainty quantification.\n",
    "\n",
    "### **Learning Objectives**\n",
    "\n",
    "By the end of this notebook series, you should be able to:\n",
    "\n",
    "1. **Understand the mathematical foundations** of diffusion processes in minerals\n",
    "2. **Implement regression techniques** using Python and SciPy\n",
    "3. **Diagnose fitting problems** and understand why optimization can fail\n",
    "4. **Visualize objective function landscapes** to understand parameter space\n",
    "5. **Apply advanced optimization strategies** for complex problems\n",
    "6. **Quantify uncertainties rigorously** using bootstrapping methods\n",
    "7. **Interpret results** in a geochemical context\n",
    "\n",
    "### **Course Structure**\n",
    "\n",
    "- **Notebook 1** (this one): Foundations and first attempts at fitting\n",
    "- **Notebook 2**: Understanding why fitting fails - objective function analysis\n",
    "- **Notebook 3**: Advanced techniques and rigorous uncertainty quantification\n",
    "\n",
    "---\n",
    "\n",
    "## Geochemical Context: Water in Olivine\n",
    "\n",
    "Olivine (Mg₂SiO₄) is the most abundant mineral in the Earth's upper mantle, controlling:\n",
    "- Mantle rheology\n",
    "- Seismic wave velocities  \n",
    "- Electrical conductivity\n",
    "- Volatile element storage and transport\n",
    "\n",
    "**The Problem:** Despite decades of research, we lack full consensus on how water is stored and diffuses in olivine. This is crucial for understanding the processes cited hereabove.\n",
    "\n",
    "**Water storage mechanisms in olivine:**\n",
    "- Si vacancies ($V_{Si}^{''''} + 4H^{•}$)\n",
    "- Mg vacancies ($V_{Mg}^{''} + 2H^•$)  \n",
    "- Associated defects with trivalent cations (Al³⁺, Fe³⁺)\n",
    "- Ti-clinohumite-like point defects\n",
    "\n",
    "### **This Course's Dataset**\n",
    "\n",
    "We'll analyze **real experimental data** from:\n",
    "\n",
    "*Le Losq, C., Jollands, M.C., Tollan, P.M.E., Hawkins, R., St. C. O'Neill, H. (2019). Point defect populations of forsterite revealed by two-stage metastable hydroxylation experiments. Contributions to Mineralogy and Petrology, 174, 53.*\n",
    "\n",
    "**Experimental conditions:**\n",
    "- Temperature: 1400 °C\n",
    "- Pressure: 1.5 GPa  \n",
    "- Duration: 192 hours\n",
    "- Sample: Forsterite single crystal (1×1×1 mm cube)\n",
    "- Analysis: LA-ICP-MS profiles\n",
    "\n",
    "---\n",
    "\n",
    "## Mathematical Foundation: Fick's Diffusion Laws\n",
    "\n",
    "Diffusion in minerals follows **Fick's laws**. For a constant surface concentration $c_0$ at $x = 0$, the analytical solution is:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "c(x,t) = c_0 \\cdot \\text{erfc}\\left(\\frac{x}{2\\sqrt{Dt}}\\right)\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "where:\n",
    "- $c(x,t)$ = concentration at distance $x$ and time $t$\n",
    "- $c_0$ = surface concentration (ppm)\n",
    "- $D$ = diffusion coefficient (m²/s)  \n",
    "- $x$ = distance from surface (m)\n",
    "- $t$ = time (s)\n",
    "- erfc = complementary error function\n",
    "\n",
    "**Key insight:** This is a **nonlinear regression problem** with parameters $D$ and $c_0$.\n",
    "\n",
    "### **Exercise 1: Visualize Diffusion Evolution**\n",
    "\n",
    "Plot concentration profiles at different times to understand the physics before attempting to fit data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361789a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(42)  # For reproducibility\n",
    "import pandas as pd\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.special import erfc\n",
    "\n",
    "# Set plotting parameters for better readability\n",
    "plt.rcParams.update({'font.size': 12, 'figure.dpi': 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdeb09e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Define the Diffusion Function\n",
    "# =============================================================================\n",
    "\n",
    "def diffusion_1d(x, t, D, c0):\n",
    "    \"\"\"\n",
    "    Analytical solution to 1D Fick's diffusion equation\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : float or array_like\n",
    "        Distance from surface in micrometers\n",
    "    t : float\n",
    "        Time in hours\n",
    "    D : float\n",
    "        Diffusion coefficient in log₁₀(m² s⁻¹)\n",
    "    c0 : float\n",
    "        Surface concentration in ppm\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    concentration : float or array_like\n",
    "        Concentration at distance x and time t\n",
    "    \"\"\"\n",
    "    # TODO: Implement the diffusion equation\n",
    "    # Remember to:\n",
    "    # 1. Handle t=0 case (avoid division by zero)\n",
    "    # 2. Convert units: x from μm to m, t from hours to seconds\n",
    "    # 3. Convert D from log₁₀ to linear scale\n",
    "    # 4. Apply the erfc solution: c0 * erfc(x / (2*sqrt(D*t)))\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    \n",
    "    \n",
    "    return # Your result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478e4698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Visualize Diffusion Evolution\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== Exercise 1: Understanding Diffusion Physics ===\")\n",
    "\n",
    "# Define parameters\n",
    "x_profile = np.arange(0, 500, 2.0)  # Distance profile (μm)\n",
    "c0_example = 100.0  # Surface concentration (ppm)\n",
    "D_example = -13.1   # log₁₀(D) typical for water in olivine at 1400°C\n",
    "\n",
    "print(f\"Parameters used:\")\n",
    "print(f\"  Surface concentration: {c0_example} ppm\")\n",
    "print(f\"  Diffusion coefficient: 10^{D_example} = {10**D_example:.2e} m²/s\")\n",
    "print(f\"  Temperature: 1400°C (experimental conditions)\")\n",
    "\n",
    "# TODO: Create a plot showing diffusion profiles at different times\n",
    "# times = [0.001, 12, 24, 48, 96, 192]  # Hours\n",
    "# Use different colors and line styles for each time\n",
    "# Add appropriate labels, title, legend\n",
    "# Calculate and show penetration depths\n",
    "\n",
    "# Your plotting code here:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddc34b5",
   "metadata": {},
   "source": [
    "## Loading and Understanding Real Experimental Data\n",
    "\n",
    "Now we transition from theory to practice. Real experimental data always presents challenges that idealized models don't capture.\n",
    "\n",
    "### **Objectives of this section:**\n",
    "- Load and visualize LA-ICP-MS diffusion profiles\n",
    "- Understand data structure and experimental uncertainties\n",
    "- Identify potential fitting challenges\n",
    "- Attempt basic curve fitting with `scipy.optimize.curve_fit`\n",
    "\n",
    "### **Why this matters in geochemistry:**\n",
    "- Experimental data contains measurement errors\n",
    "- Spatial resolution limitations\n",
    "\n",
    "### **Data description:**\n",
    "- **Sample**: Forsterite single crystal (Mg₂SiO₄)\n",
    "- **Technique**: Laser Ablation ICP-MS (LA-ICP-MS)\n",
    "- **Elements**: Fe, Al, Sc, Ti (trace elements)\n",
    "- **Two orientations**: [100] and [001] (different crystallographic directions)\n",
    "\n",
    "**Ultimate goals for this course:**\n",
    "1. ✅ Fit diffusion coefficients for multiple elements\n",
    "2. ✅ Provide rigorous uncertainty estimates  \n",
    "3. ✅ Compare results between crystallographic orientations\n",
    "4. ✅ Interpret results in terms of defect chemistry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804a4344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Load and Explore Experimental Data\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== Loading LA-ICP-MS Diffusion Profile Data ===\")\n",
    "\n",
    "# TODO: Load the experimental datasets\n",
    "# Files: \"./data/16C_ICP1_1400C_axisC_192h_FoEn.csv\" and \"./data/16C_ICP2_1400C_axisA_192h_FoEn.csv\"\n",
    "# Use pandas.read_csv(), for example => pd.read_csv(\"./data/16C_ICP1_1400C_axisC_192h_FoEn.csv\")\n",
    "\n",
    "# Your code here:\n",
    "data_AxisC = \n",
    "data_AxisA = \n",
    "\n",
    "# TODO: Explore the data structure\n",
    "# Print shapes, column names, basic statistics\n",
    "\n",
    "print(\"Axis C dataset (parallel to [001] direction):\")\n",
    "# Your exploration code here:\n",
    "\n",
    "\n",
    "print(f\"\\nAxis A dataset (parallel to [100] direction):\")\n",
    "# Your exploration code here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55dffc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Data Quality Assessment\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n=== Data Quality Assessment ===\")\n",
    "\n",
    "# TODO: Extract key variables for analysis\n",
    "# Get Distance and Fe_ppm_m57 columns from AxisC data\n",
    "x_AxisC = \n",
    "Fe_AxisC = \n",
    "\n",
    "\n",
    "# TODO: Estimate measurement uncertainties\n",
    "# Use: max(10% of concentration, 5 ppm minimum)\n",
    "# Hint: np.maximum(0.1 * Fe_AxisC, 5.0)\n",
    "Fe_error_AxisC = \n",
    "\n",
    "print(f\"\\nEstimated uncertainties:\")\n",
    "# Print uncertainty statistics here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3aff320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Data Visualization\n",
    "# =============================================================================\n",
    "\n",
    "# TODO: Create a two-panel figure\n",
    "# Panel 1: Axis C profile with error bars + theoretical comparison\n",
    "# Panel 2: Both orientations comparison\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Panel 1: Your plotting code here\n",
    "# Use errorbar() to show data with uncertainties\n",
    "# Add a theoretical profile for comparison (D ≈ -14.0)\n",
    "\n",
    "\n",
    "\n",
    "# Panel 2: Your comparison plotting code here\n",
    "# Show both AxisC and AxisA data\n",
    "# Extract AxisA data first: x_AxisA, Fe_AxisA, Fe_error_AxisA\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e867365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Initial Data Analysis\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n=== Initial Data Analysis ===\")\n",
    "\n",
    "# TODO: Analyze profile characteristics\n",
    "# Find surface concentration (max), background (min)\n",
    "# Find distance where concentration = 50% of maximum\n",
    "\n",
    "# Your analysis code here:\n",
    "\n",
    "\n",
    "# TODO: Make a rough diffusion coefficient estimate\n",
    "# Use: D ≈ (penetration_distance)^2 / (4 * time)\n",
    "# Remember unit conversions!\n",
    "\n",
    "t_experiment = 192.0  # hours\n",
    "# Your estimation code here:\n",
    "\n",
    "\n",
    "print(f\"\\n=== Key Observations ===\")\n",
    "print(f\"✓ Data show expected diffusion behavior (high→low concentration)\")\n",
    "print(f\"✓ Crystallographic anisotropy is evident ([100] ≠ [001])\")\n",
    "print(f\"⚠ Scatter in data suggests measurement uncertainties\")\n",
    "print(f\"⚠ Limited data points for robust fitting\")\n",
    "print(f\"⚠ Background concentration is not zero (core composition)\")\n",
    "print(f\"\\n➜ Challenge: How to fit these noisy, limited data robustly?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27d1e7",
   "metadata": {},
   "source": [
    "## First Attempt at Curve Fitting\n",
    "\n",
    "Now let's attempt to fit our theoretical diffusion model to the experimental data using `scipy.optimize.curve_fit`, the standard tool for nonlinear regression in Python.\n",
    "\n",
    "### **The Regression Problem**\n",
    "\n",
    "\n",
    "The general idea is to define a model *m* which fits our data *d* with some parameters we can tune. We basically want to map:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "d = g(m)\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "with $g$ the mapping function and $m$ the model (set of model parameters).\n",
    "\n",
    "In our case, we want to find the best values of $D$ and $c_0$ (and potentially a background concentration $c_{bg}$) that minimize the difference between our model and the data.\n",
    "\n",
    "**Modified forward model for realistic data:**\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "c(x,t) = (c_0 - c_{bg}) \\cdot \\text{erfc}\\left(\\frac{x}{2\\sqrt{Dt}}\\right) + c_{bg}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "**Parameters to fit:**\n",
    "- $D$: diffusion coefficient (log₁₀ m²/s)  \n",
    "- $c_0$: rim concentration (ppm)\n",
    "- $c_{bg}$: background/core concentration (ppm)\n",
    " In this case, $g$ is the equation 2 and $m$ are the $D$, $c0$ and $c_{bg}$ parameters.\n",
    "\n",
    "**Least-square regression**\n",
    "\n",
    "An easy and well used way to fit our data with eq. 2 is to use least-square regression. The least-square problem consists in minimizing the misfit between the observation $d$ and the model predictions $g(m)$:\n",
    "\n",
    "$\n",
    "\\begin{align}\n",
    "misfit = \\sum_{i=1}^{n}{(d_i-g_i(m))^2}\n",
    "\\end{align}\n",
    "$\n",
    "\n",
    "We want to minimize this value. Eq. 4 is called the **objective function** or **misfit function** of our problem. Eq. 4 is a least-square objective function. Other functions can be used, like the least absolute value objective function (a.k.a. L1 norm).\n",
    "\n",
    "There is several way to do that. In Python, one of the simplest is to **use the curve_fit function of scipy**. In order to use this function, we need to have another one that allows calculating eq. 3. Let's do that.\n",
    "\n",
    "### **Why might fitting fail?**\n",
    "\n",
    "Before we start, let's consider potential challenges:\n",
    "1. **Parameter scaling**: $D$ values span many orders of magnitude\n",
    "2. **Parameter correlation**: $D$, $c_0$, and $c_{bg}$ may be correlated\n",
    "3. **Initial guesses**: Nonlinear optimization needs good starting points\n",
    "4. **Local minima**: The objective function may have complex topology\n",
    "5. **Data quality**: Limited points, measurement errors, outliers\n",
    "\n",
    "Let's see what happens with a naive approach..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924f259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Define the Forward Model for Fitting\n",
    "# =============================================================================\n",
    "\n",
    "def forward_model_3param(x, D, c_rim, c_bg):\n",
    "    \"\"\"\n",
    "    Three-parameter diffusion model for fitting experimental data\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        Distance from rim in micrometers\n",
    "    D : float\n",
    "        Diffusion coefficient in log10(m^2 s^-1)\n",
    "    c_rim : float\n",
    "        Rim concentration in ppm\n",
    "    c_bg : float\n",
    "        Background/core concentration in ppm\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    concentration : array_like\n",
    "        Predicted concentration at each distance x\n",
    "    \"\"\"\n",
    "    # TODO: Implement the three-parameter model\n",
    "    # 1. Define experimental time (192 hours in seconds)\n",
    "    # 2. Convert x from μm to m\n",
    "    # 3. Convert D from log to linear scale\n",
    "    # 4. Apply erfc solution with background: (c_rim - c_bg) * erfc(...) + c_bg\n",
    "    \n",
    "    # Your code here:\n",
    "    \n",
    "    \n",
    "    \n",
    "    return # Your result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd714905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Attempt Curve Fitting\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== Attempt 1: Naive curve_fit (default settings) ===\")\n",
    "\n",
    "# TODO: Try fitting with default initial guesses (this may fail!)\n",
    "\n",
    "# Use curve_fit with no initial guesses\n",
    "# Your code here:\n",
    "popt_naive, pcov_naive = \n",
    "\n",
    "print(\"Naive fitting succeeded (surprisingly!):\")\n",
    "print(f\"  D = {popt_naive[0]:.2f} (log₁₀ m²/s)\")\n",
    "print(f\"  c_rim = {popt_naive[1]:.1f} ppm\")\n",
    "print(f\"  c_bg = {popt_naive[2]:.1f} ppm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67278a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Smart Initial Guesses\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n=== Attempt 2: Intelligent Parameter Initialization ===\")\n",
    "\n",
    "# TODO: Create smart initial guesses based on data inspection\n",
    "# D: typical value for Fe in olivine at 1400°C (around -14.0)\n",
    "# c_rim: maximum concentration in data\n",
    "# c_bg: minimum concentration in data\n",
    "\n",
    "D_init = \n",
    "c_rim_init = \n",
    "c_bg_init = \n",
    "\n",
    "initial_guesses = [D_init, c_rim_init, c_bg_init]\n",
    "print(f\"Initial guesses:\")\n",
    "print(f\"  D = {D_init} (log₁₀ m²/s)\")\n",
    "print(f\"  c_rim = {c_rim_init:.1f} ppm\")  \n",
    "print(f\"  c_bg = {c_bg_init:.1f} ppm\")\n",
    "\n",
    "# TODO: Try fitting with smart initial guesses and uncertainties\n",
    "\n",
    "# Use curve_fit with p0=initial_guesses, sigma=Fe_error_AxisC, absolute_sigma=True\n",
    "# Your code here:\n",
    "popt_smart, pcov_smart = \n",
    "\n",
    "print(f\"\\nSmart fitting results:\")\n",
    "print(f\"  D = {popt_smart[0]:.3f} ± {np.sqrt(pcov_smart[0,0]):.3f} (log₁₀ m²/s)\")\n",
    "print(f\"  c_rim = {popt_smart[1]:.1f} ± {np.sqrt(pcov_smart[1,1]):.1f} ppm\")\n",
    "print(f\"  c_bg = {popt_smart[2]:.1f} ± {np.sqrt(pcov_smart[2,2]):.1f} ppm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55e4df2",
   "metadata": {},
   "source": [
    "## Understanding Chi-Square Statistics for Fit Quality Assessment\n",
    "\n",
    "Before analyzing our fitting results, let's understand the **chi-square (χ²) statistics** that quantify how well our model matches the data.\n",
    "\n",
    "### **Chi-Square ($\\chi^2$) Statistic:**\n",
    "\n",
    "The chi-square statistic measures the weighted sum of squared residuals:\n",
    "\n",
    "$$\\chi^2 = \\sum_{i=1}^{n} \\left(\\frac{y_i - f(x_i, \\theta)}{\\sigma_i}\\right)^2$$\n",
    "\n",
    "where:\n",
    "- $y_i$ = observed data point\n",
    "- $f(x_i, \\theta)$ = model prediction at $x_i$ with parameters $\\theta$\n",
    "- $\\sigma_i$ = uncertainty (error bar) for data point $i$\n",
    "- $n$ = number of data points\n",
    "\n",
    "### **Reduced Chi-Square ($\\chi^2_\\nu$):**\n",
    "\n",
    "The reduced chi-square normalizes by degrees of freedom:\n",
    "\n",
    "$$\\chi^2_\\nu = \\frac{\\chi^2}{\\nu} = \\frac{\\chi^2}{n - p}$$\n",
    "\n",
    "where:\n",
    "- $\\nu$ = degrees of freedom = $n - p$\n",
    "- $p$ = number of fitted parameters\n",
    "\n",
    "### **Interpretation Guidelines:**\n",
    "\n",
    "**For a good fit with properly estimated uncertainties:**\n",
    "- **$\\chi^2_\\nu$ ≈ 1** -> residuals are consistent with estimated errors;\n",
    "- **$\\chi^2_\\nu$ << 1** -> Either over-fitting or overestimated uncertainties;\n",
    "- **$\\chi^2_\\nu$ >> 1** -> Either poor model fit or underestimated uncertainties;\n",
    "\n",
    "### **Practical Thresholds:**\n",
    "- **$\\chi^2_\\nu$ < 0.5**: Suspicious - check error estimates\n",
    "- **0.5 ≤ $\\chi^2_\\nu$ ≤ 2.0**: Acceptable fit quality\n",
    "- **$\\chi^2_\\nu$ > 2.0**: Poor fit - model or error issues\n",
    "\n",
    "### **Why This Matters in Geochemistry:**\n",
    "- **Validates analytical uncertainties**: Are our error bars realistic?\n",
    "- **Guides model selection**: Is our model appropriate?\n",
    "- **Informs experimental design**: What precision do we need?\n",
    "- **Quality control**: Identifies outliers or systematic problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f1e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Visualization and Statistical Analysis\n",
    "# =============================================================================\n",
    "\n",
    "# TODO: Create detailed visualization with two panels\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Panel 1: Data and fit\n",
    "# Plot experimental data with error bars\n",
    "# Plot fitted model (use fine x grid for smooth curve)\n",
    "# Your plotting code here:\n",
    "\n",
    "\n",
    "\n",
    "# Panel 2: Residuals analysis\n",
    "# Calculate residuals: data - model\n",
    "# Plot residuals with error bars\n",
    "# Add reference lines (y=0, ±1σ)\n",
    "# Your residuals plotting code here:\n",
    "residuals = \n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# TODO: Statistical analysis\n",
    "print(f\"\\n=== Statistical Analysis ===\")\n",
    "print(f\"Residual statistics:\")\n",
    "# Print mean, std, max absolute residual\n",
    "# Your statistics code here:\n",
    "\n",
    "\n",
    "# TODO: Chi-square analysis\n",
    "# Calculate chi-square and reduced chi-square\n",
    "# Interpret the results\n",
    "# Your chi-square code here:\n",
    "chi_squared = \n",
    "degrees_of_freedom = \n",
    "reduced_chi_squared = \n",
    "\n",
    "print(f\"  χ² = {chi_squared:.1f} (sum of weighted squared residuals)\")\n",
    "print(f\"  Degrees of freedom = {degrees_of_freedom} ({len(Fe_AxisC)} points - 3 parameters)\")\n",
    "print(f\"  Reduced χ² = {reduced_chi_squared:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f933d85",
   "metadata": {},
   "source": [
    "## Creating Synthetic Data for Method Development\n",
    "\n",
    "Before tackling the challenges with real data, let's create synthetic (artificial) data where we know the \"true\" parameters. This allows us to:\n",
    "\n",
    "1. **Test our fitting algorithms** under controlled conditions\n",
    "2. **Understand the effects of noise** on parameter recovery\n",
    "3. **Validate our approach** before applying it to real data\n",
    "4. **Explore the parameter space** systematically\n",
    "\n",
    "### **Why playing with synthetic data matters:**\n",
    "- **Method validation**: Prove algorithms work before applying to expensive experimental data\n",
    "- **Error analysis**: Understand how measurement uncertainties propagate to parameter uncertainties\n",
    "- **Experimental design**: Optimize sampling strategies and analytical protocols\n",
    "- **Hypothesis testing**: Test whether proposed models can explain observations\n",
    "\n",
    "This approach is standard practice in computational geochemistry and geophysics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0e7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Generate Synthetic Data\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== Generating Synthetic Diffusion Data ===\")\n",
    "\n",
    "# TODO: Define \"true\" parameters (what we want to recover)\n",
    "D_true = -14.5          # log₁₀(m²/s)\n",
    "c_rim_true = 95.0       # ppm\n",
    "c_bg_true = 8.0         # ppm\n",
    "\n",
    "print(f\"True parameters (what we want to recover):\")\n",
    "print(f\"  D_true = {D_true} (log₁₀ m²/s)\")  \n",
    "print(f\"  c_rim_true = {c_rim_true} ppm\")\n",
    "print(f\"  c_bg_true = {c_bg_true} ppm\")\n",
    "\n",
    "# TODO: Create synthetic measurement locations\n",
    "# Use np.arange(0, 120, 3.0) for every 3 μm from 0 to 120 μm\n",
    "x_synthetic = \n",
    "\n",
    "# TODO: Generate perfect synthetic data\n",
    "y_synthetic_perfect = \n",
    "\n",
    "# TODO: Add realistic noise\n",
    "# Set noise level (5 ppm typical for LA-ICP-MS)\n",
    "# Add Gaussian noise with np.random.normal()\n",
    "# Create variable error bars\n",
    "np.random.seed(42)  # For reproducible results\n",
    "noise_level = 5.0\n",
    "# Your noise code here:\n",
    "noise = \n",
    "y_synthetic_noisy = \n",
    "error_synthetic = \n",
    "\n",
    "print(f\"  Noise level: {noise_level} ppm (1σ)\")\n",
    "print(f\"  Signal-to-noise ratio: {np.max(y_synthetic_perfect)/noise_level:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf4ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Fit Synthetic Data\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n=== Fitting Synthetic Data (Should Work Well) ===\")\n",
    "\n",
    "# TODO: Create initial guesses (slightly off from true values)\n",
    "D_init_syn = -14.0      # Close but not exact\n",
    "c_rim_init_syn = 100.0  # Close but not exact  \n",
    "c_bg_init_syn = 5.0     # Close but not exact\n",
    "\n",
    "initial_guesses_syn = [D_init_syn, c_rim_init_syn, c_bg_init_syn]\n",
    "\n",
    "# TODO: Fit the synthetic data\n",
    "\n",
    "# Use curve_fit with synthetic data and initial guesses\n",
    "# Your fitting code here:\n",
    "popt_syn, pcov_syn = \n",
    "\n",
    "# TODO: Calculate parameter uncertainties and recovery errors\n",
    "param_errors_syn = \n",
    "\n",
    "print(f\"Fitting results:\")\n",
    "print(f\"  D = {popt_syn[0]:.3f} ± {param_errors_syn[0]:.3f} (true: {D_true})\")\n",
    "print(f\"  c_rim = {popt_syn[1]:.1f} ± {param_errors_syn[1]:.1f} (true: {c_rim_true})\")  \n",
    "print(f\"  c_bg = {popt_syn[2]:.1f} ± {param_errors_syn[2]:.1f} (true: {c_bg_true})\")\n",
    "\n",
    "# TODO: Check parameter recovery (how close are we to true values?)\n",
    "# Your recovery analysis here:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb0dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# EXERCISE: Comprehensive Visualization of Synthetic Results\n",
    "# =============================================================================\n",
    "\n",
    "# TODO: Create a 2x2 subplot figure\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Panel 1: Synthetic data and fit\n",
    "# Show: noisy data, perfect model, fitted model\n",
    "# Your plotting code here:\n",
    "\n",
    "\n",
    "# Panel 2: Residuals for synthetic data\n",
    "# Show residuals with error bars and reference lines\n",
    "# Your residuals code here:\n",
    "\n",
    "\n",
    "# Panel 3: Parameter correlation matrix\n",
    "# Calculate and visualize correlation matrix\n",
    "# Your correlation code here:\n",
    "correlation_matrix = \n",
    "\n",
    "\n",
    "# Panel 4: Real vs synthetic comparison\n",
    "# Compare real and synthetic fitting results\n",
    "# Your comparison code here:\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3a77c1",
   "metadata": {},
   "source": [
    "## Summary and Preview of Advanced Techniques\n",
    "\n",
    "### **What we've learned in Notebook 1:**\n",
    "\n",
    "1. **✅ Theoretical foundation**: Fick's diffusion equation and its analytical solution\n",
    "2. **✅ Real data challenges**: Experimental uncertainties, limited sampling, background concentrations  \n",
    "3. **✅ Basic regression**: Using `scipy.optimize.curve_fit` for nonlinear fitting\n",
    "4. **✅ Parameter initialization**: The critical importance of good starting guesses\n",
    "5. **✅ Method validation**: Using synthetic data to test algorithms\n",
    "6. **✅ Statistical analysis**: Residuals, correlation matrices, goodness-of-fit metrics\n",
    "\n",
    "### **Key challenges identified:**\n",
    "\n",
    "- **Parameter scaling**: Diffusion coefficients span many orders of magnitude\n",
    "- **Parameter correlation**: D, c_rim, and c_bg are often strongly correlated\n",
    "- **Local minima**: Nonlinear optimization can get trapped in suboptimal solutions\n",
    "- **Uncertainty quantification**: How reliable are the error bars from curve_fit?\n",
    "\n",
    "### **What's coming next:**\n",
    "\n",
    "**Notebook 2: Understanding Optimization Landscapes**\n",
    "- Visualize the objective function in parameter space\n",
    "- Understand why local algorithms fail\n",
    "- Compare least squares vs. least absolute deviations\n",
    "- Explore global optimization strategies\n",
    "\n",
    "**Notebook 3: Rigorous Uncertainty Quantification**  \n",
    "- Limitations of covariance-based uncertainties\n",
    "- Bootstrap methods for robust error estimation\n",
    "- Confidence intervals for predictions\n",
    "- Real-world application to multiple elements\n",
    "\n",
    "---\n",
    "\n",
    "### **The Bigger Picture: Why This Matters in Geochemistry**\n",
    "\n",
    "Robust parameter estimation is crucial for:\n",
    "- **Process understanding**: Inferring diffusion mechanisms and defect chemistry\n",
    "- **Extrapolation**: Predicting behavior at different T-P-t conditions\n",
    "- **Comparison**: Benchmarking experimental results across studies\n",
    "- **Modeling**: Parameterizing large-scale geodynamic models\n",
    "\n",
    "The techniques we're developing apply broadly to:\n",
    "- Kinetic experiments (diffusion, dissolution, crystallization)\n",
    "- Thermobarometry and geothermometry\n",
    "- Isotope systematics and geochronology\n",
    "- Spectroscopic analysis and calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d0900b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# Exercises for Students\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=== EXERCISES FOR STUDENTS ===\")\n",
    "print(\"\\nTry these exercises to deepen your understanding:\")\n",
    "\n",
    "print(\"\\n1. PARAMETER SENSITIVITY ANALYSIS\")\n",
    "print(\"   Modify the true parameters in the synthetic data generation:\")\n",
    "print(\"   - Try D_true = -15.0 (slower diffusion)\")\n",
    "print(\"   - Try D_true = -13.0 (faster diffusion)\")  \n",
    "print(\"   - How does this affect fitting success and parameter uncertainties?\")\n",
    "\n",
    "print(\"\\n2. NOISE LEVEL INVESTIGATION\")\n",
    "print(\"   Change the noise_level parameter:\")\n",
    "print(\"   - Try noise_level = 2.0 (better precision)\")\n",
    "print(\"   - Try noise_level = 10.0 (worse precision)\")\n",
    "print(\"   - How does measurement precision affect parameter recovery?\")\n",
    "\n",
    "print(\"\\n3. SAMPLING DENSITY EXPERIMENT\")  \n",
    "print(\"   Modify the synthetic data spacing:\")\n",
    "print(\"   - Try x_synthetic = np.arange(0, 120, 6.0)  # Fewer points\")\n",
    "print(\"   - Try x_synthetic = np.arange(0, 120, 1.5)  # More points\")\n",
    "print(\"   - What's the minimum sampling needed for robust fitting?\")\n",
    "\n",
    "print(\"\\n4. ALTERNATIVE ELEMENTS\")\n",
    "print(\"   Try fitting other elements from the dataset:\")\n",
    "print(\"   - Al_ppm_m27 (aluminum)\")  \n",
    "print(\"   - Ti_ppm_m49 (titanium)\")\n",
    "print(\"   - How do diffusion coefficients compare between elements?\")\n",
    "\n",
    "print(\"\\n5. CRYSTALLOGRAPHIC ANISOTROPY\")\n",
    "print(\"   Compare fitting results between Axis A and Axis C orientations:\")\n",
    "print(\"   - Fit the same element in both directions\")\n",
    "print(\"   - Calculate the anisotropy ratio: D_AxisC / D_AxisA\")\n",
    "print(\"   - Which direction shows faster diffusion?\")\n",
    "\n",
    "# =============================================================================\n",
    "# Template Code for Student Exercises\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n=== TEMPLATE CODE FOR EXERCISE 4 ===\")\n",
    "print(\"# Try fitting aluminum instead of iron:\")\n",
    "print(\"# Al_FoEn = data_FoEn['Al_ppm_m27'].values\")\n",
    "print(\"# Al_error_FoEn = np.maximum(0.1 * Al_FoEn, 2.0)\")\n",
    "print(\"# \")\n",
    "print(\"# popt_Al, pcov_Al = curve_fit(forward_model_3param,\")  \n",
    "print(\"#                              x_FoEn, Al_FoEn,\")\n",
    "print(\"#                              p0=[-14.0, np.max(Al_FoEn), np.min(Al_FoEn)],\")\n",
    "print(\"#                              sigma=Al_error_FoEn,\")\n",
    "print(\"#                              absolute_sigma=True)\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
